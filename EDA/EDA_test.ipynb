{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bba458d",
   "metadata": {},
   "source": [
    "# Comprehensive Data Analysis - Test Dataset\n",
    "\n",
    "This notebook provides a thorough exploratory data analysis of the test.csv dataset, focusing on:\n",
    "- Data structure and basic information\n",
    "- Missing values analysis\n",
    "- Duplicate detection\n",
    "- Statistical summaries\n",
    "- Test vs Training data comparison (matching analyze_data.py)\n",
    "- Anchor weather analysis\n",
    "- Data visualization\n",
    "- Column-wise analysis\n",
    "- Understanding the prediction task structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36eca801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create graphs directory if it doesn't exist\n",
    "graphs_dir = 'graphs'\n",
    "if not os.path.exists(graphs_dir):\n",
    "    os.makedirs(graphs_dir)\n",
    "    print(f\"Created directory: {graphs_dir}\")\n",
    "else:\n",
    "    print(f\"Directory {graphs_dir} already exists\")\n",
    "\n",
    "# Create test graphs directory if it doesn't exist\n",
    "test_graphs_dir = f'{graphs_dir}/test_graphs_dir'\n",
    "if not os.path.exists(test_graphs_dir):\n",
    "    os.makedirs(test_graphs_dir)\n",
    "    print(f\"Created directory: {test_graphs_dir}\")\n",
    "else:\n",
    "    print(f\"Directory {test_graphs_dir} already exists\")\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette('husl')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb552051",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b27ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test dataset\n",
    "test_df = pd.read_csv('../data/test.csv')\n",
    "\n",
    "print(\"=== TEST DATASET ===\")\n",
    "print(f\"Shape: {test_df.shape}\")\n",
    "print(f\"Columns: {list(test_df.columns)}\")\n",
    "print(\"\\nColumn descriptions:\")\n",
    "print(\"- row_id: Unique identifier for each prediction row\")\n",
    "print(\"- item_id: Location identifier (Location4)\")\n",
    "print(\"- anchor_time: The reference time point\")\n",
    "print(\"- Time: The target prediction time (anchor_time + 24h)\")\n",
    "print(\"- anchor_*: Weather covariates at the anchor time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd27a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus on test dataset for detailed analysis\n",
    "dataset_df = test_df.copy()\n",
    "\n",
    "# Analyze dataset\n",
    "dataset_head = dataset_df.head().to_string()\n",
    "dataset_tails = dataset_df.tail().to_string()\n",
    "dataset_shape = dataset_df.shape\n",
    "rows, cols = dataset_shape\n",
    "\n",
    "# Inspect and log head, tail, dimensions and shape\n",
    "print(f\"Dataset head:\\n{dataset_head}\")\n",
    "print(f\"\\nDataset tail:\\n{dataset_tails}\")\n",
    "print(f\"\\nDataset shape: {dataset_shape}\")\n",
    "print(f\"Dataset has {cols} columns and {rows} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e44275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all columns are shown when printing\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Summary statistics of numeric columns\n",
    "numeric_cols = dataset_df.select_dtypes(include=[np.number]).columns\n",
    "print(\"Summary statistics:\\n\", dataset_df[numeric_cols].describe())\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "# Check for missing data\n",
    "missing_values = dataset_df.isnull().sum()\n",
    "print(f\"Missing values per column:\\n{missing_values}\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "# Check for duplicate rows\n",
    "duplicate_rows = dataset_df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicate_rows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7021f487",
   "metadata": {},
   "source": [
    "## 2. Data Type Analysis and Time Column Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c6d160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types\n",
    "print(\"Data types:\")\n",
    "print(dataset_df.dtypes)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Convert Time columns to datetime\n",
    "dataset_df['anchor_time'] = pd.to_datetime(dataset_df['anchor_time'])\n",
    "dataset_df['Time'] = pd.to_datetime(dataset_df['Time'])\n",
    "print(f\"Anchor time range: {dataset_df['anchor_time'].min()} to {dataset_df['anchor_time'].max()}\")\n",
    "print(f\"Target time range: {dataset_df['Time'].min()} to {dataset_df['Time'].max()}\")\n",
    "\n",
    "# Verify the 24-hour prediction window\n",
    "time_diff = (dataset_df['Time'] - dataset_df['anchor_time']).dt.total_seconds() / 3600\n",
    "print(f\"\\nTime difference between anchor and target (hours): {time_diff.unique()}\")\n",
    "\n",
    "# Check unique locations\n",
    "print(f\"\\nUnique locations: {dataset_df['item_id'].unique()}\")\n",
    "print(f\"Number of unique locations: {dataset_df['item_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204a9874",
   "metadata": {},
   "source": [
    "## 3. Row ID Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5d226d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze row_id structure\n",
    "print(\"Sample row_id values:\")\n",
    "print(dataset_df['row_id'].head(10).tolist())\n",
    "print(\"\\nRow ID structure analysis:\")\n",
    "print(\"Format appears to be: Location4_YYYYMMDDHHMM_T24\")\n",
    "print(\"Where:\")\n",
    "print(\"- Location4: The location identifier\")\n",
    "print(\"- YYYYMMDDHHMM: Timestamp in format (anchor_time)\")\n",
    "print(\"- T24: Indicates 24-hour ahead prediction\")\n",
    "\n",
    "# Extract timestamp from row_id and verify consistency\n",
    "def extract_timestamp_from_row_id(row_id):\n",
    "    parts = row_id.split('_')\n",
    "    if len(parts) >= 2:\n",
    "        timestamp_str = parts[1]\n",
    "        return pd.to_datetime(timestamp_str, format='%Y%m%d%H%M')\n",
    "    return None\n",
    "\n",
    "dataset_df['extracted_time'] = dataset_df['row_id'].apply(extract_timestamp_from_row_id)\n",
    "time_consistency = (dataset_df['extracted_time'] == dataset_df['anchor_time']).all()\n",
    "print(f\"\\nTime consistency between row_id and anchor_time: {time_consistency}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf540257",
   "metadata": {},
   "source": [
    "## 4. Weather Variables Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f54f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get weather columns (anchor_* columns)\n",
    "weather_columns = [col for col in dataset_df.columns if col.startswith('anchor_') and dataset_df[col].dtype in ['int64', 'float64']]\n",
    "print(f\"Weather variables: {weather_columns}\")\n",
    "print(f\"Number of weather variables: {len(weather_columns)}\")\n",
    "\n",
    "# Create a mapping of weather variables to their descriptions\n",
    "weather_descriptions = {\n",
    "    'anchor_temperature_2m': 'Temperature at 2m height (°F)',\n",
    "    'anchor_relativehumidity_2m': 'Relative humidity at 2m height (%)',\n",
    "    'anchor_dewpoint_2m': 'Dew point at 2m height (°F)',\n",
    "    'anchor_windspeed_10m': 'Wind speed at 10m height (mph)',\n",
    "    'anchor_windspeed_100m': 'Wind speed at 100m height (mph)',\n",
    "    'anchor_winddirection_10m': 'Wind direction at 10m height (degrees)',\n",
    "    'anchor_winddirection_100m': 'Wind direction at 100m height (degrees)',\n",
    "    'anchor_windgusts_10m': 'Wind gusts at 10m height (mph)'\n",
    "}\n",
    "\n",
    "print(\"\\nWeather variable descriptions:\")\n",
    "for var, desc in weather_descriptions.items():\n",
    "    print(f\"- {var}: {desc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test_vs_train_comparison",
   "metadata": {},
   "source": [
    "## 5. Test vs Training Data Comparison (from analyze_data.py)\n",
    "\n",
    "This section replicates the comparison analysis from analyze_data.py to understand how test data relates to training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_train_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data for comparison\n",
    "train_df = pd.read_csv('../data/train.csv')\n",
    "train_df['Time'] = pd.to_datetime(train_df['Time'])\n",
    "\n",
    "# Filter Location4 from training data\n",
    "loc4_train = train_df[train_df['item_id'] == 'Location4']\n",
    "\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Location4 training data shape: {loc4_train.shape}\")\n",
    "print(f\"Test data shape: {dataset_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weather_comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data anchor weather vs training weather comparison (matching analyze_data.py)\n",
    "print(\"Test data anchor weather vs training weather comparison:\")\n",
    "print(f\"Test anchor wind speeds (10m): {dataset_df['anchor_windspeed_10m'].describe()}\")\n",
    "print(f\"\\nTraining wind speeds (10m): {loc4_train['windspeed_10m'].describe()}\")\n",
    "\n",
    "print(f\"\\nTest anchor wind speeds (100m): {dataset_df['anchor_windspeed_100m'].describe()}\")\n",
    "print(f\"\\nTraining wind speeds (100m): {loc4_train['windspeed_100m'].describe()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed_comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed comparison of all weather variables\n",
    "print(\"\\nDetailed Weather Variable Comparison:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Map anchor columns to training columns\n",
    "comparison_mapping = {\n",
    "    'anchor_temperature_2m': 'temperature_2m',\n",
    "    'anchor_relativehumidity_2m': 'relativehumidity_2m',\n",
    "    'anchor_dewpoint_2m': 'dewpoint_2m',\n",
    "    'anchor_windspeed_10m': 'windspeed_10m',\n",
    "    'anchor_windspeed_100m': 'windspeed_100m',\n",
    "    'anchor_winddirection_10m': 'winddirection_10m',\n",
    "    'anchor_winddirection_100m': 'winddirection_100m',\n",
    "    'anchor_windgusts_10m': 'windgusts_10m'\n",
    "}\n",
    "\n",
    "for test_col, train_col in comparison_mapping.items():\n",
    "    print(f\"\\n{test_col.replace('anchor_', '').upper()}:\")\n",
    "    print(f\"  Test (anchor) - Mean: {dataset_df[test_col].mean():.2f}, Std: {dataset_df[test_col].std():.2f}\")\n",
    "    print(f\"  Train        - Mean: {loc4_train[train_col].mean():.2f}, Std: {loc4_train[train_col].std():.2f}\")\n",
    "    print(f\"  Difference   - Mean: {dataset_df[test_col].mean() - loc4_train[train_col].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparison_visualization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison visualizations\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (test_col, train_col) in enumerate(comparison_mapping.items()):\n",
    "    # Create histograms for comparison\n",
    "    axes[i].hist(loc4_train[train_col], bins=20, alpha=0.7, label='Training', color='blue', density=True)\n",
    "    axes[i].hist(dataset_df[test_col], bins=20, alpha=0.7, label='Test (anchor)', color='red', density=True)\n",
    "    axes[i].set_title(f'{test_col.replace(\"anchor_\", \"\").replace(\"_\", \" \").title()}')\n",
    "    axes[i].set_xlabel('Value')\n",
    "    axes[i].set_ylabel('Density')\n",
    "    axes[i].legend()\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{test_graphs_dir}/test_vs_train_weather_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"Saved: {test_graphs_dir}/test_vs_train_weather_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "temporal_comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal comparison - show when test period occurs relative to training\n",
    "print(\"\\nTemporal Analysis:\")\n",
    "print(f\"Training period: {loc4_train['Time'].min()} to {loc4_train['Time'].max()}\")\n",
    "print(f\"Test anchor period: {dataset_df['anchor_time'].min()} to {dataset_df['anchor_time'].max()}\")\n",
    "print(f\"Test target period: {dataset_df['Time'].min()} to {dataset_df['Time'].max()}\")\n",
    "\n",
    "# Check if there's any overlap\n",
    "train_end = loc4_train['Time'].max()\n",
    "test_start = dataset_df['anchor_time'].min()\n",
    "gap_days = (test_start - train_end).days\n",
    "print(f\"\\nGap between training end and test start: {gap_days} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "time_series_viz",
   "metadata": {},
   "source": [
    "## 6. Time-Based Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58aacbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time series plots for all weather variables\n",
    "print(f\"Creating time series plots for {len(weather_columns)} weather variables\")\n",
    "\n",
    "# Create subplot grid - use 3x3 to ensure we have enough subplots\n",
    "fig, axes = plt.subplots(3, 3, figsize=(18, 15))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(weather_columns):\n",
    "    if i < len(axes):  # Safety check\n",
    "        axes[i].plot(dataset_df['anchor_time'], dataset_df[col], marker='o', linewidth=2, markersize=4)\n",
    "        axes[i].set_title(f'{col} over Time', fontsize=12, fontweight='bold')\n",
    "        axes[i].set_xlabel('Anchor Time')\n",
    "        axes[i].set_ylabel(weather_descriptions.get(col, col))\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "        axes[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Hide unused subplots\n",
    "for i in range(len(weather_columns), len(axes)):\n",
    "    axes[i].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{test_graphs_dir}/weather_variables_timeseries.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"Saved: {test_graphs_dir}/weather_variables_timeseries.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597cac71",
   "metadata": {},
   "source": [
    "## 7. Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5387bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create distribution plots for all weather variables\n",
    "print(f\"Creating distribution plots for {len(weather_columns)} weather variables\")\n",
    "\n",
    "# Create subplot grid - use 3x3 to ensure we have enough subplots\n",
    "fig, axes = plt.subplots(3, 3, figsize=(18, 15))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(weather_columns):\n",
    "    if i < len(axes):  # Safety check\n",
    "        # Histogram\n",
    "        axes[i].hist(dataset_df[col], bins=15, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "        axes[i].set_title(f'Distribution of {col}', fontsize=12, fontweight='bold')\n",
    "        axes[i].set_xlabel(weather_descriptions.get(col, col))\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add statistics text\n",
    "        mean_val = dataset_df[col].mean()\n",
    "        std_val = dataset_df[col].std()\n",
    "        axes[i].axvline(mean_val, color='red', linestyle='--', alpha=0.8, label=f'Mean: {mean_val:.2f}')\n",
    "        axes[i].legend()\n",
    "\n",
    "# Hide unused subplots\n",
    "for i in range(len(weather_columns), len(axes)):\n",
    "    axes[i].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{test_graphs_dir}/weather_variables_distributions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"Saved: {test_graphs_dir}/weather_variables_distributions.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec419e7",
   "metadata": {},
   "source": [
    "## 8. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af7745f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix for weather variables\n",
    "weather_data = dataset_df[weather_columns]\n",
    "correlation_matrix = weather_data.corr()\n",
    "\n",
    "# Create correlation heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": .8}, fmt='.3f')\n",
    "plt.title('Correlation Matrix of Weather Variables', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{test_graphs_dir}/weather_correlation_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"Saved: {test_graphs_dir}/weather_correlation_matrix.png\")\n",
    "\n",
    "# Print high correlations\n",
    "print(\"\\nHigh correlations (|r| > 0.7):\")\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        corr_val = correlation_matrix.iloc[i, j]\n",
    "        if abs(corr_val) > 0.7:\n",
    "            print(f\"{correlation_matrix.columns[i]} vs {correlation_matrix.columns[j]}: {corr_val:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c80dde",
   "metadata": {},
   "source": [
    "## 9. Wind Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c31d231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wind speed comparison (10m vs 100m)\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(dataset_df['anchor_windspeed_10m'], dataset_df['anchor_windspeed_100m'], alpha=0.7)\n",
    "plt.xlabel('Wind Speed at 10m (mph)')\n",
    "plt.ylabel('Wind Speed at 100m (mph)')\n",
    "plt.title('Wind Speed: 10m vs 100m Height')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add diagonal line for reference\n",
    "min_val = min(dataset_df['anchor_windspeed_10m'].min(), dataset_df['anchor_windspeed_100m'].min())\n",
    "max_val = max(dataset_df['anchor_windspeed_10m'].max(), dataset_df['anchor_windspeed_100m'].max())\n",
    "plt.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.5, label='Equal speeds')\n",
    "plt.legend()\n",
    "\n",
    "# Wind direction comparison (10m vs 100m)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(dataset_df['anchor_winddirection_10m'], dataset_df['anchor_winddirection_100m'], alpha=0.7)\n",
    "plt.xlabel('Wind Direction at 10m (degrees)')\n",
    "plt.ylabel('Wind Direction at 100m (degrees)')\n",
    "plt.title('Wind Direction: 10m vs 100m Height')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add diagonal line for reference\n",
    "plt.plot([0, 360], [0, 360], 'r--', alpha=0.5, label='Equal directions')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{test_graphs_dir}/wind_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"Saved: {test_graphs_dir}/wind_analysis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683b5b27",
   "metadata": {},
   "source": [
    "## 10. Temporal Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d43240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract temporal features\n",
    "dataset_df['month'] = dataset_df['anchor_time'].dt.month\n",
    "dataset_df['day_of_week'] = dataset_df['anchor_time'].dt.dayofweek\n",
    "dataset_df['hour'] = dataset_df['anchor_time'].dt.hour\n",
    "\n",
    "# Create temporal analysis plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Monthly patterns for temperature\n",
    "monthly_temp = dataset_df.groupby('month')['anchor_temperature_2m'].agg(['mean', 'std']).reset_index()\n",
    "axes[0, 0].errorbar(monthly_temp['month'], monthly_temp['mean'], yerr=monthly_temp['std'], \n",
    "                   marker='o', capsize=5, capthick=2)\n",
    "axes[0, 0].set_title('Monthly Temperature Patterns')\n",
    "axes[0, 0].set_xlabel('Month')\n",
    "axes[0, 0].set_ylabel('Temperature (°F)')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Daily patterns for wind speed\n",
    "daily_wind = dataset_df.groupby('day_of_week')['anchor_windspeed_10m'].agg(['mean', 'std']).reset_index()\n",
    "day_names = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "axes[0, 1].errorbar(daily_wind['day_of_week'], daily_wind['mean'], yerr=daily_wind['std'], \n",
    "                   marker='o', capsize=5, capthick=2)\n",
    "axes[0, 1].set_title('Daily Wind Speed Patterns')\n",
    "axes[0, 1].set_xlabel('Day of Week')\n",
    "axes[0, 1].set_ylabel('Wind Speed (mph)')\n",
    "axes[0, 1].set_xticks(range(7))\n",
    "axes[0, 1].set_xticklabels(day_names)\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Hourly patterns (all data is at 12:00, so this will be uniform)\n",
    "hourly_temp = dataset_df.groupby('hour')['anchor_temperature_2m'].agg(['mean', 'count']).reset_index()\n",
    "axes[1, 0].bar(hourly_temp['hour'], hourly_temp['count'])\n",
    "axes[1, 0].set_title('Hourly Distribution of Data Points')\n",
    "axes[1, 0].set_xlabel('Hour of Day')\n",
    "axes[1, 0].set_ylabel('Count')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Time series of all anchor times\n",
    "axes[1, 1].plot(dataset_df['anchor_time'], dataset_df['anchor_temperature_2m'], 'o-', alpha=0.7)\n",
    "axes[1, 1].set_title('Temperature Time Series')\n",
    "axes[1, 1].set_xlabel('Anchor Time')\n",
    "axes[1, 1].set_ylabel('Temperature (°F)')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{test_graphs_dir}/temporal_patterns.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"Saved: {test_graphs_dir}/temporal_patterns.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fd3c41",
   "metadata": {},
   "source": [
    "## 11. Statistical Summary and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab6349c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive statistical summary\n",
    "# Force correct weather_columns definition to avoid datetime errors\n",
    "weather_columns = [col for col in dataset_df.columns if col.startswith('anchor_') and dataset_df[col].dtype in ['int64', 'float64']]\n",
    "print(\"=== TEST DATASET STATISTICAL SUMMARY ===\")\n",
    "print(f\"Total number of predictions required: {len(dataset_df)}\")\n",
    "print(f\"Prediction period: {dataset_df['anchor_time'].min().strftime('%Y-%m-%d')} to {dataset_df['anchor_time'].max().strftime('%Y-%m-%d')}\")\n",
    "print(f\"All predictions are for Location: {dataset_df['item_id'].unique()[0]}\")\n",
    "print(f\"Prediction horizon: 24 hours ahead\")\n",
    "print(f\"All anchor times are at: {dataset_df['hour'].unique()[0]}:00 (noon)\")\n",
    "\n",
    "print(\"\\n=== WEATHER VARIABLE RANGES ===\")\n",
    "# Filter to only numeric weather columns to avoid datetime formatting errors\n",
    "numeric_weather_cols = [col for col in weather_columns if dataset_df[col].dtype in ['int64', 'float64']]\n",
    "print(f\"Analyzing {len(numeric_weather_cols)} numeric weather variables\")\n",
    "for col in numeric_weather_cols:\n",
    "    min_val = dataset_df[col].min()\n",
    "    max_val = dataset_df[col].max()\n",
    "    mean_val = dataset_df[col].mean()\n",
    "    std_val = dataset_df[col].std()\n",
    "    print(f\"{col}:\")\n",
    "    print(f\"  Range: {min_val:.2f} to {max_val:.2f}\")\n",
    "    print(f\"  Mean ± Std: {mean_val:.2f} ± {std_val:.2f}\")\n",
    "\n",
    "print(\"\\n=== DATA QUALITY ASSESSMENT ===\")\n",
    "print(f\"Missing values: {dataset_df.isnull().sum().sum()}\")\n",
    "print(f\"Duplicate rows: {dataset_df.duplicated().sum()}\")\n",
    "print(f\"Data completeness: {(1 - dataset_df.isnull().sum().sum() / (len(dataset_df) * len(dataset_df.columns))) * 100:.1f}%\")\n",
    "\n",
    "print(\"\\n=== KEY INSIGHTS ===\")\n",
    "print(\"1. This is a next-day power prediction task for Location4\")\n",
    "print(\"2. All predictions are made at noon (12:00) for the next day at noon\")\n",
    "print(\"3. Weather covariates are provided at the anchor time only\")\n",
    "print(\"4. The dataset covers approximately 2 months of predictions\")\n",
    "print(\"5. No missing values - clean dataset ready for modeling\")\n",
    "print(\"6. Wind speeds are consistently higher at 100m than at 10m height\")\n",
    "print(\"7. Wind directions at different heights are highly correlated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa9927d",
   "metadata": {},
   "source": [
    "## 12. Comparison with Training Data Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710a976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data for comparison\n",
    "try:\n",
    "    train_df = pd.read_csv('../data/train.csv')\n",
    "    train_df['Time'] = pd.to_datetime(train_df['Time'])\n",
    "    \n",
    "    print(\"=== COMPARISON WITH TRAINING DATA ===\")\n",
    "    print(f\"Training data period: {train_df['Time'].min().strftime('%Y-%m-%d')} to {train_df['Time'].max().strftime('%Y-%m-%d')}\")\n",
    "    print(f\"Test data period: {dataset_df['anchor_time'].min().strftime('%Y-%m-%d')} to {dataset_df['anchor_time'].max().strftime('%Y-%m-%d')}\")\n",
    "    \n",
    "    # Check if test period follows training period\n",
    "    train_end = train_df['Time'].max()\n",
    "    test_start = dataset_df['anchor_time'].min()\n",
    "    \n",
    "    print(f\"\\nTime gap between training end and test start: {(test_start - train_end).days} days\")\n",
    "    \n",
    "    # Location4 data in training set\n",
    "    loc4_train = train_df[train_df['item_id'] == 'Location4']\n",
    "    print(f\"\\nLocation4 in training data:\")\n",
    "    print(f\"  Records: {len(loc4_train)}\")\n",
    "    print(f\"  Period: {loc4_train['Time'].min().strftime('%Y-%m-%d')} to {loc4_train['Time'].max().strftime('%Y-%m-%d')}\")\n",
    "    print(f\"  Power range: {loc4_train['Power'].min():.4f} to {loc4_train['Power'].max():.4f}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"Training data not found for comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c56582d",
   "metadata": {},
   "source": [
    "## 13. Feature Engineering Suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9932e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== FEATURE ENGINEERING SUGGESTIONS ===\")\n",
    "print(\"\\nBased on the test data analysis, consider these features:\")\n",
    "print(\"\\n1. TEMPORAL FEATURES:\")\n",
    "print(\"   - Month, day of year, day of week\")\n",
    "print(\"   - Season indicators\")\n",
    "print(\"   - Days since/until solstices and equinoxes\")\n",
    "\n",
    "print(\"\\n2. WEATHER INTERACTIONS:\")\n",
    "print(\"   - Wind power proxy: windspeed^3 (cube of wind speed)\")\n",
    "print(\"   - Temperature-humidity interactions\")\n",
    "print(\"   - Wind shear: difference between 100m and 10m speeds\")\n",
    "print(\"   - Wind direction consistency between heights\")\n",
    "\n",
    "print(\"\\n3. LAGGED FEATURES (from training data):\")\n",
    "print(\"   - Previous day's power output\")\n",
    "print(\"   - Rolling averages of weather variables (3, 7, 30 days)\")\n",
    "print(\"   - Weather change rates (day-to-day differences)\")\n",
    "\n",
    "print(\"\\n4. DERIVED WEATHER FEATURES:\")\n",
    "print(\"   - Heat index (temperature + humidity)\")\n",
    "print(\"   - Wind chill factor\")\n",
    "print(\"   - Atmospheric pressure proxy (temperature + humidity)\")\n",
    "print(\"   - Wind direction in radians (sin/cos transformation)\")\n",
    "\n",
    "print(\"\\n5. POWER-SPECIFIC FEATURES:\")\n",
    "print(\"   - Optimal wind speed ranges for power generation\")\n",
    "print(\"   - Temperature efficiency factors\")\n",
    "print(\"   - Seasonal power generation patterns\")\n",
    "\n",
    "# Demonstrate some feature engineering\n",
    "print(\"\\n=== EXAMPLE FEATURE ENGINEERING ===\")\n",
    "dataset_df['wind_power_proxy'] = dataset_df['anchor_windspeed_100m'] ** 3\n",
    "dataset_df['wind_shear'] = dataset_df['anchor_windspeed_100m'] - dataset_df['anchor_windspeed_10m']\n",
    "dataset_df['temp_humidity_interaction'] = dataset_df['anchor_temperature_2m'] * dataset_df['anchor_relativehumidity_2m']\n",
    "dataset_df['wind_direction_consistency'] = abs(dataset_df['anchor_winddirection_100m'] - dataset_df['anchor_winddirection_10m'])\n",
    "\n",
    "print(\"Created example features:\")\n",
    "print(f\"- wind_power_proxy: mean = {dataset_df['wind_power_proxy'].mean():.2f}\")\n",
    "print(f\"- wind_shear: mean = {dataset_df['wind_shear'].mean():.2f}\")\n",
    "print(f\"- temp_humidity_interaction: mean = {dataset_df['temp_humidity_interaction'].mean():.2f}\")\n",
    "print(f\"- wind_direction_consistency: mean = {dataset_df['wind_direction_consistency'].mean():.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
